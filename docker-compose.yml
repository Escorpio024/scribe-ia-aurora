services:
  scribe_api:
    build: .
    image: scribe-ia:latest
    container_name: scribe_api
    env_file: .env
    ports:
      - "${API_PORT:-8080}:8080"
    volumes:
      - ./knowledge:/app/knowledge
      - ./data:/data
      - ./tmp:/tmp
    depends_on:
      - scribe_ollama
      - hapi

  scribe_ollama:
    image: ollama/ollama:latest
    container_name: scribe_ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ./ollama:/root/.ollama
    # Descarga modelo en primer arranque (opcional)
    entrypoint: ["/bin/sh","-lc","ollama serve & sleep 2 && ollama pull llama3:8b && tail -f /dev/null"]

  hapi:
    image: hapiproject/hapi:latest
    container_name: hapi
    environment:
      - hapi.fhir.allow_cascading_deletes=true
    ports:
      - "8081:8080"